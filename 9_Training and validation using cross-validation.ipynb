{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dad3204",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lightgbm import LGBMClassifier\n",
    "from lightgbm import early_stopping, log_evaluation, record_evaluation\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fbba2b",
   "metadata": {},
   "source": [
    "# Read the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643143d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "working_directory = os.getcwd()\n",
    "print(working_directory)\n",
    "data = pd.read_csv(f\"{working_directory}/Input_Data/creditcard_post_correlation.csv\") #Change the path to your dataset, if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f32295",
   "metadata": {},
   "source": [
    "## Define Predictors and Target Variables\n",
    "##### We will specify the predictor features and the target variable. Additionally, categorical features can be identified if present. In this case, there are no categorical features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ba8047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the target variable\n",
    "target = 'Fraud_Flag'\n",
    "\n",
    "# Define the features to be used in the model\n",
    "predictors = [\n",
    "    'Transaction_Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
    "    'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19',\n",
    "    'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28',\n",
    "    'Transaction_Amount'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4ec111",
   "metadata": {},
   "source": [
    "## Define the TRAIN/VALIDATION/TEST SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e8039c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAIN/VALIDATION/TEST SPLIT\n",
    "#VALIDATION\n",
    "VALID_SIZE = 0.20 # simple validation using train_test_split\n",
    "TEST_SIZE = 0.20 # test size using_train_test_split\n",
    "\n",
    "#CROSS-VALIDATION\n",
    "NUMBER_KFOLDS = 5 #number of KFolds for cross-validation\n",
    "\n",
    "RANDOM_STATE = 2018\n",
    "\n",
    "MAX_ROUNDS = 1000 #lgb iterations\n",
    "EARLY_STOP = 50 #lgb early stop \n",
    "OPT_ROUNDS = 1000  #To be adjusted based on best validation rounds\n",
    "VERBOSE_EVAL = 50 #Print out metric result\n",
    "\n",
    "# Set the path to the input data\n",
    "IS_LOCAL = True  # Set to True since you we running locally\n",
    "\n",
    "if IS_LOCAL:\n",
    "    PATH = \"C:/Users/teovr/Desktop/Credit_Card_Fraud_Detection_Predictive_Model/Input_Data/\"\n",
    "else:\n",
    "    PATH = \"../input\"\n",
    "\n",
    "print(os.listdir(PATH))  # List the files in the specified directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42c3ad2",
   "metadata": {},
   "source": [
    "## Split data in train, test and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194f4032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "train_df, test_df = train_test_split(\n",
    "    data, \n",
    "    test_size=TEST_SIZE, \n",
    "    random_state=RANDOM_STATE, \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Further split the training set into training and validation sets\n",
    "train_df, valid_df = train_test_split(\n",
    "    train_df, \n",
    "    test_size=VALID_SIZE, \n",
    "    random_state=RANDOM_STATE, \n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b210be7",
   "metadata": {},
   "source": [
    "## Training and validation using cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9b4406",
   "metadata": {},
   "source": [
    "##### Let's apply cross-validation. We will use 5-fold cross-validation (KFold), where the data is split into 5 folds. In each iteration, the model is trained on 4 folds and validated on the remaining fold.\n",
    "\n",
    "The final test set performance is computed as the average of the predictions across all folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aae4ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize KFold\n",
    "kf = KFold(n_splits=NUMBER_KFOLDS, random_state=RANDOM_STATE, shuffle=True)\n",
    "\n",
    "# Define evaluation results dictionary\n",
    "evals_results = {}\n",
    "\n",
    "# Create arrays and dataframes to store results\n",
    "oof_preds = np.zeros(train_df.shape[0])\n",
    "test_preds = np.zeros(test_df.shape[0])\n",
    "feature_importance_df = pd.DataFrame()\n",
    "n_fold = 0\n",
    "\n",
    "# K-Fold training loop\n",
    "for train_idx, valid_idx in kf.split(train_df):\n",
    "    train_x, train_y = train_df[predictors].iloc[train_idx], train_df[target].iloc[train_idx]\n",
    "    valid_x, valid_y = train_df[predictors].iloc[valid_idx], train_df[target].iloc[valid_idx]\n",
    "    \n",
    "    evals_results = {}\n",
    "\n",
    "    model = LGBMClassifier(\n",
    "        nthread=-1,\n",
    "        n_estimators=2000,\n",
    "        learning_rate=0.01,\n",
    "        num_leaves=80,\n",
    "        colsample_bytree=0.98,\n",
    "        subsample=0.78,\n",
    "        reg_alpha=0.04,\n",
    "        reg_lambda=0.073,\n",
    "        subsample_for_bin=50,\n",
    "        boosting_type='gbdt',\n",
    "        is_unbalance=False,\n",
    "        min_split_gain=0.025,\n",
    "        min_child_weight=40,\n",
    "        min_child_samples=510,\n",
    "        objective='binary'\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "    train_x, train_y,\n",
    "    eval_set=[(train_x, train_y), (valid_x, valid_y)],\n",
    "    eval_metric='auc',\n",
    "    callbacks=[\n",
    "        early_stopping(EARLY_STOP),\n",
    "        log_evaluation(VERBOSE_EVAL),\n",
    "        record_evaluation(evals_results)\n",
    "    ]\n",
    ")\n",
    "    # Predict on validation and test set\n",
    "    oof_preds[valid_idx] = model.predict_proba(valid_x, num_iteration=model.best_iteration_)[:, 1]\n",
    "    test_preds += model.predict_proba(test_df[predictors], num_iteration=model.best_iteration_)[:, 1] / kf.n_splits\n",
    "\n",
    "    # Record feature importance\n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"feature\"] = predictors\n",
    "    fold_importance_df[\"importance\"] = model.feature_importances_\n",
    "    fold_importance_df[\"fold\"] = n_fold + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "\n",
    "    # Print fold AUC\n",
    "    print(f'Fold {n_fold + 1} AUC : {roc_auc_score(valid_y, oof_preds[valid_idx]):.6f}')\n",
    "\n",
    "    # Clean up\n",
    "    del model, train_x, train_y, valid_x, valid_y\n",
    "    gc.collect()\n",
    "    n_fold += 1\n",
    "\n",
    "# Full validation score\n",
    "train_auc_score = roc_auc_score(train_df[target], oof_preds)\n",
    "print(f'Full AUC score {train_auc_score:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4062d7",
   "metadata": {},
   "source": [
    "##### The AUC score for the prediction from the test data was 0.97.\n",
    "\n",
    "##### We prepare the test prediction, from the averaged predictions for test over the 5 folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcc3739",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions6 = test_preds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
