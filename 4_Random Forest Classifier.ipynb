{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ad60e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812c623c",
   "metadata": {},
   "source": [
    "# Read the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f16a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "working_directory = os.getcwd()\n",
    "print(working_directory)\n",
    "data = pd.read_csv(f\"{working_directory}/Input_Data/creditcard_post_correlation.csv\") #Change the path to your dataset, if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c82f997",
   "metadata": {},
   "source": [
    "## Define Predictors and Target Variables\n",
    "##### We will specify the predictor features and the target variable. Additionally, categorical features can be identified if present. In this case, there are no categorical features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08558f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the target variable\n",
    "target = 'Fraud_Flag'\n",
    "\n",
    "# Define the features to be used in the model\n",
    "predictors = [\n",
    "    'Transaction_Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
    "    'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19',\n",
    "    'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28',\n",
    "    'Transaction_Amount'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ff3405",
   "metadata": {},
   "source": [
    "## Define the TRAIN/VALIDATION/TEST SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520f991f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAIN/VALIDATION/TEST SPLIT\n",
    "#VALIDATION\n",
    "VALID_SIZE = 0.20 # simple validation using train_test_split\n",
    "TEST_SIZE = 0.20 # test size using_train_test_split\n",
    "\n",
    "#CROSS-VALIDATION\n",
    "NUMBER_KFOLDS = 5 #number of KFolds for cross-validation\n",
    "\n",
    "RANDOM_STATE = 2018\n",
    "\n",
    "MAX_ROUNDS = 1000 #lgb iterations\n",
    "EARLY_STOP = 50 #lgb early stop \n",
    "OPT_ROUNDS = 1000  #To be adjusted based on best validation rounds\n",
    "VERBOSE_EVAL = 50 #Print out metric result\n",
    "\n",
    "# Set the path to the input data\n",
    "IS_LOCAL = True  # Set to True since you we running locally\n",
    "\n",
    "if IS_LOCAL:\n",
    "    PATH = \"C:/Users/teovr/Desktop/Credit_Card_Fraud_Detection_Predictive_Model/Input_Data/\"\n",
    "else:\n",
    "    PATH = \"../input\"\n",
    "\n",
    "print(os.listdir(PATH))  # List the files in the specified directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd422b7d",
   "metadata": {},
   "source": [
    "## Split data in train, test and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8daacc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "train_df, test_df = train_test_split(\n",
    "    data, \n",
    "    test_size=TEST_SIZE, \n",
    "    random_state=RANDOM_STATE, \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Further split the training set into training and validation sets\n",
    "train_df, valid_df = train_test_split(\n",
    "    train_df, \n",
    "    test_size=VALID_SIZE, \n",
    "    random_state=RANDOM_STATE, \n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca3208d",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da244ded",
   "metadata": {},
   "source": [
    "##### We are going to start with a RandomForrestClassifier model.\n",
    "##### Let's set the parameters for the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c3b6c1",
   "metadata": {},
   "source": [
    "### Random Forrest Classifier definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec56d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "RFC_METRIC = 'gini'  #metric used for RandomForrestClassifier\n",
    "NUM_ESTIMATORS = 100 #number of estimators used for RandomForrestClassifier\n",
    "NUMBER_OF_JOBS = 4 #number of parallel jobs used for RandomForrestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93e623e",
   "metadata": {},
   "source": [
    "#### The model will be trained using the training set and evaluated on the validation set.\n",
    "\n",
    "#### The GINI coefficient, calculated as GINI = 2 * (AUC) - 1 (where AUC is the Area Under the Receiver Operating Characteristic Curve), will be used as the validation metric. The number of estimators is set to 100, and the model will utilize 4 parallel jobs.\n",
    "\n",
    "#### The process begins by initializing the Random Forest Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d2b78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the RandomForestClassifier\n",
    "clf = RandomForestClassifier(\n",
    "    n_jobs=NUMBER_OF_JOBS,       # Number of parallel jobs\n",
    "    random_state=RANDOM_STATE,   # Random seed for reproducibility\n",
    "    criterion=RFC_METRIC,        # Splitting criterion (e.g., 'gini')\n",
    "    n_estimators=NUM_ESTIMATORS, # Number of trees in the forest\n",
    "    verbose=False                # Suppress verbose output\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764224d3",
   "metadata": {},
   "source": [
    "##### Train the Randon Forest Classifier using the train_df data and fit function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c11f45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(train_df[predictors], train_df[target].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada6d2ca",
   "metadata": {},
   "source": [
    "##### Use the predict function to predict the target values for the valid_df data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbcb3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict(valid_df[predictors])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bf22e0",
   "metadata": {},
   "source": [
    "##### We will also visualize the features importance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abc2410",
   "metadata": {},
   "source": [
    "### Features importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eae984a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame to store feature importance\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': predictors,\n",
    "    'Importance': clf.feature_importances_\n",
    "})\n",
    "\n",
    "# Sort the features by importance in descending order\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot the feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title('Feature Importance', fontsize=18, fontweight='bold')\n",
    "sns.barplot(\n",
    "    x='Feature',\n",
    "    y='Importance',\n",
    "    hue='Feature',  \n",
    "    data=feature_importance_df,\n",
    "    palette='crest',  \n",
    "    dodge=False  \n",
    ")\n",
    "plt.legend([], [], frameon=False)  \n",
    "plt.xticks(rotation=45, fontsize=10, ha='right')\n",
    "plt.xlabel('Features', fontsize=14, labelpad=10)\n",
    "plt.ylabel('Importance', fontsize=14, labelpad=10)\n",
    "plt.tight_layout()  \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51ef67a",
   "metadata": {},
   "source": [
    "##### The most important features are V17, V12, V14, V10, V11, V16."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330ac407",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a854cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the confusion matrix\n",
    "cm = pd.crosstab(\n",
    "    valid_df[target].values, \n",
    "    predictions, \n",
    "    rownames=['Actual'], \n",
    "    colnames=['Predicted']\n",
    ")\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(6, 6))  \n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt='d',\n",
    "    cmap=\"Blues\",\n",
    "    linewidths=1,\n",
    "    linecolor=\"black\",\n",
    "    cbar=False,\n",
    "    xticklabels=['Not Fraud', 'Fraud'],\n",
    "    yticklabels=['Not Fraud', 'Fraud'],\n",
    "    annot_kws={\"size\": 18, \"weight\": \"bold\"}\n",
    ")\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Confusion Matrix', fontsize=16, fontweight='bold', pad=15)\n",
    "plt.xlabel('Predicted', fontsize=14, labelpad=10)\n",
    "plt.ylabel('Actual', fontsize=14, labelpad=10)\n",
    "\n",
    "# Adjust layout and display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e96ed0",
   "metadata": {},
   "source": [
    "### Type I and Type II Errors:\n",
    "\n",
    "##### It is important to note that confusion matrices are not ideal for evaluating results in cases of highly imbalanced datasets. In such scenarios, alternative metrics that consider both the sensitivity (true positive rate) and specificity (true negative rate) of the model are more appropriate. These metrics help minimize both Type I and Type II errors simultaneously.\n",
    "\n",
    "##### Null Hypothesis (H₀): The transaction is not fraudulent.\n",
    "\n",
    "##### Alternative Hypothesis (H₁): The transaction is fraudulent.\n",
    "\n",
    "##### Type I Error: Occurs when the null hypothesis is rejected even though it is true. In this context, it means incorrectly classifying a legitimate transaction as fraudulent.\n",
    "\n",
    "##### Cost of Type I Error: A valid transaction is mistakenly flagged as fraud, leading to its rejection.\n",
    "##### Type II Error: Occurs when the null hypothesis is not rejected even though the alternative hypothesis is true. In this context, it means failing to identify a fraudulent transaction.\n",
    "\n",
    "##### Cost of Type II Error: A fraudulent transaction is mistakenly classified as legitimate, allowing it to proceed undetected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5e5fe6",
   "metadata": {},
   "source": [
    "### ROC-AUC score (Area under curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f637a77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(valid_df[target].values, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942cbcbd",
   "metadata": {},
   "source": [
    "##### The ROC-AUC score obtained with RandomForrestClassifier is 0.85."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
